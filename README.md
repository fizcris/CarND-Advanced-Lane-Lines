## Advanced Lane Finding
[![Udacity - Self-Driving Car NanoDegree](https://s3.amazonaws.com/udacity-sdc/github/shield-carnd.svg)](http://www.udacity.com/drive)
![Lanes Image](./examples/example_output.jpg)

In this project, your goal is to write a software pipeline to identify the lane boundaries in a video.


The Project
---

The goals / steps of this project are the following:

* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.
* Apply a distortion correction to raw images.
* Use color transforms, gradients, etc., to create a thresholded binary image.
* Apply a perspective transform to rectify binary image ("birds-eye view").
* Detect lane pixels and fit to find the lane boundary.
* Determine the curvature of the lane and vehicle position with respect to center.
* Warp the detected lane boundaries back onto the original image.
* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.
***
Note that all the notebooks need the helper functions script `0. Functions_Clases Pipeline.py` that is auto generated by the notebook `0. Functions_Clases Pipeline.ipynb` when it is executed. All the requirements to run the notebooks should be in the `pickle_data` folder. This project uses picke files wich is a way to pass data from notebook to notebook.
***
# 1. Camera calibration

The code for this section is contained in the Jupyter notebook `1. Camera Calibration Parameters.ipynb`.

 You need to set your chessboard size to 9x6 for the project

I start by preparing "object points", which will be the (x, y, z) coordinates of the chessboard corners in the world. Here I am assuming the chessboard is fixed on the (x, y) plane at z=0, such that the object points are the same for each calibration image. Thus, objp is just a replicated array of coordinates, and objpoints will be appended with a copy of it every time I successfully detect all chessboard corners in a test image. imgpoints will be appended with the (x, y) pixel position of each of the corners in the image plane with each successful chessboard detection.

I then used the output objpoints and imgpoints to compute the camera calibration and distortion coefficients using the cv2.calibrateCamera() function. I applied this distortion correction to the test image using the cv2.undistort() function and obtained this result:

# 2. Image undistortion
The code for this section is contained in the Jupyter notebook `2. Image undistortion.ipynb`. 

# 3. Color enhancement and filtering
The code for this section is contained in the Jupyter notebook `3. Color Enhancement.ipynb`. 

# 4. Edge detection
The code for this section is contained in the Jupyter notebook `4. Edge detection.ipynb`. 

# 5. Region of interest masking
The code for this section is contained in the Jupyter notebook `5. Region of interest.ipynb`. 

# 6. Perspective tranform (birds eye)
The code for this section is contained in the Jupyter notebook `6. Perspective transform.ipynb`. 

# 7. Finding lines
The code for this section is contained in the Jupyter notebook `7. Finding Lines.ipynb`. 

# 8. Image unwarping
The code for this section is contained in the Jupyter notebook `8. Unwarp Images.ipynb`. 

# 9. Curvature radius and vehicle position
The code for this section is contained in the Jupyter notebook `9. Anotate Images.ipynb`. 

# 10. Video pipeline
The code for this section is contained in the Jupyter notebook `10. Videos Pipeline.ipynb`. 

# 11. Profiling Video pipeline
The code for this section is contained in the Jupyter notebook `11. Profiling Videos Pipeline.ipynb`. 
****


































To help the reviewer examine your work, please save examples of the output from each stage of your pipeline in the folder called `output_images`, and include a description in your writeup for the project of what each image shows.    The video called `project_video.mp4` is the video your pipeline should work well on.  






# Images Pipeline

* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.
* Apply a distortion correction to raw images.
* Use color transforms, gradients, etc., to create a thresholded binary image.
* Apply a perspective transform to rectify binary image ("birds-eye view").
* Detect lane pixels and fit to find the lane boundary.
* Determine the curvature of the lane and vehicle position with respect to center.
* Warp the detected lane boundaries back onto the original image.
* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.