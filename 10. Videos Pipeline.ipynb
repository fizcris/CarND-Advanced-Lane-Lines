{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13d48ba",
   "metadata": {},
   "source": [
    "# Videos Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "853e34a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 0. Functions_Clases Pipeline.ipynb to script\n",
      "[NbConvertApp] Writing 19720 bytes to 0. Functions_Clases Pipeline.py\n"
     ]
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "# load helper functions\n",
    "%run -i \"0. Functions_Clases Pipeline.py\"\n",
    "%run -i \"Line.py\"\n",
    "\n",
    "# Load Camera calibration params\n",
    "[ret, mtx, dist, rvecs, tvecs] = pickle.load(open( \"pickle_data/camera_calibration_params.p\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32dad634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(img):\n",
    "    \n",
    "    ###### Resize image\n",
    "    img = resizeImage(img)\n",
    "\n",
    "    ###### Undistort image\n",
    "    undistorted = undistort_image(img, mtx, dist)\n",
    "  \n",
    "    ###### Color Enhancement\n",
    "\n",
    "    imageCE = colorEnhancement(img)\n",
    "   \n",
    "    ###### GrayScale\n",
    "    imageGray = grayscale(imageCE)\n",
    "\n",
    "\n",
    "    ###### Gauss Smoothing\n",
    "    imageGauss = gaussian_blur(imageGray,kernel_size=5) \n",
    "    \n",
    "    #### Edge detection\n",
    "    sbinary = sobel_thresh(imageGauss, sobel_kernel=5, x_thresh=[80,100], y_thresh=[40,100], mag_thresh=[50,255], dir_thresh=[100,200])\n",
    "\n",
    "    #### ROI\n",
    "    ysize =sbinary.shape[0]\n",
    "    xsize =sbinary.shape[1]\n",
    "\n",
    "    ROI_upperWidth = 350 #Width of the upper horizontal straight in px\n",
    "    ROI_upperHeight = 300 #Height of the upper horizontal straight from the bottom of the image in px\n",
    "    ROI_lowerWidth = 1000 #Width of the lower horizontal straight in px\n",
    "    ROI_lowerHeight = 50  #Height of the lower horizontal straight  from the bottom of the image in px      \n",
    "\n",
    "    limitLL = ((xsize/2)-(ROI_lowerWidth/2),ysize-ROI_lowerHeight);\n",
    "    limitLR = (xsize - ((xsize/2)-(ROI_lowerWidth/2)),ysize-ROI_lowerHeight);\n",
    "    limitUL = ((xsize/2)-(ROI_upperWidth/2), ysize-ROI_upperHeight);\n",
    "    limitUR = ((xsize/2)+(ROI_upperWidth/2), ysize-ROI_upperHeight);\n",
    "    vertices = np.array([[limitLL,limitUL,limitUR , limitLR]], dtype=np.int32)\n",
    "    \n",
    "    imageROI = region_of_interest(sbinary,vertices)\n",
    "\n",
    "    \n",
    "    #### Perspective transform\n",
    "    warped_img,M, Minv = warp_image(imageROI, hwidth = 250 ,offset = 0, height = -600, overplotLines= False )\n",
    "    \n",
    "    #### Find lines\n",
    "    \n",
    "    # Find x line poitns based on histogram values\n",
    "    leftx_base, rightx_base  = find_lane_x_points(warped_img)\n",
    "    \n",
    "    # Update x base points\n",
    "    lineLeft.updateXbase(leftx_base)\n",
    "    lineRight.updateXbase(rightx_base)\n",
    "    \n",
    "    \n",
    "    #Speed up coef with area search\n",
    "    #Left line\n",
    "    if lineLeft.missdetections > 0 or np.any((lineLeft.recent_poly_fits == 0)):\n",
    "        ## Find lane pixels\n",
    "        leftx, lefty, rightx, righty, out_img = find_lane_pixels(warped_img, lineLeft.bestx, lineRight.bestx, showRectangles = False)\n",
    "        \n",
    "        ## Update lane pixels\n",
    "        lineLeft.updatePixels(leftx, lefty)   \n",
    "\n",
    "        # Search blindly image\n",
    "        coeffs_fit_L, lineDetectedL, left_fitx, ploty, img_line  = fit_polynomial(out_img, lineLeft.allx, lineLeft.ally, drawPoly = False)\n",
    "        \n",
    "    else:\n",
    "        # Search based on coefs\n",
    "        leftx, lefty, coeffs_fit_L, lineDetectedL, left_fitx, out_img = search_around_poly(warped_img, lineLeft)\n",
    "        lineLeft.updatePixels(leftx, lefty)  \n",
    "\n",
    "    #Right line\n",
    "    if lineRight.missdetections > 0 or np.any((lineRight.recent_poly_fits == 0)):\n",
    "        ## Update lane pixels\n",
    "        if not(\"rightx\" in locals()) or not(\"righty\" in locals()) :\n",
    "            leftx, lefty, rightx, righty, out_img = find_lane_pixels(warped_img, lineLeft.bestx, lineRight.bestx, showRectangles = False)\n",
    "\n",
    "        lineRight.updatePixels(rightx, righty)\n",
    "        \n",
    "        # Search blindly image\n",
    "        coeffs_fit_R, lineDetectedR, right_fitx, ploty, img_line  = fit_polynomial(out_img, lineRight.allx, lineRight.ally, drawPoly = False)\n",
    "    else:\n",
    "        # Search based on coefs\n",
    "        rightx, righty, coeffs_fit_R, lineDetectedR, right_fitx, out_img = search_around_poly(out_img, lineRight)   \n",
    "        lineRight.updatePixels(rightx, righty)\n",
    "        \n",
    "           \n",
    "    #Update line class instances\n",
    "\n",
    "    lineLeft.updateCoeffsLine(lineDetectedL, coeffs_fit_L, left_fitx, lineLeft.poly_ploty,coefLimits=[0.01,1,100],movingAvg=5 )\n",
    "    lineRight.updateCoeffsLine(lineDetectedR, coeffs_fit_R,right_fitx,lineRight.poly_ploty,coefLimits=[0.01,1,100],movingAvg=5 )\n",
    "    \n",
    "        \n",
    "    \n",
    "    ### Unwarp images\n",
    "    \n",
    "    #color_warp = np.zeros_like(out_img).astype(np.uint8)\n",
    "    color_warp = out_img\n",
    "    #color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    pts_left = np.array([np.transpose(np.vstack([lineLeft.poly_plotx, lineLeft.poly_ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([lineRight.poly_plotx, lineRight.poly_ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "     \n",
    "    #Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "    \n",
    "    newwarp = cv2.warpPerspective(color_warp, M, (img.shape[1], img.shape[0])) \n",
    "    result = cv2.addWeighted(img, 1, newwarp, 0.8, 0)\n",
    "    \n",
    "    \n",
    "    ### Anotate Radius of curvature\n",
    "    diff, mean, text = checkRadius(lineLeft, lineRight )\n",
    "\n",
    "    result_annotated = cv2.putText(result, text, org= (50, 50), fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   fontScale=2, color= (255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "    \n",
    "\n",
    "    ### Anotate Vehicle position\n",
    "    dev, text = calculateDeviation(result, lineLeft,lineRight,)\n",
    "\n",
    "    result_annotated = cv2.putText(result, text, org= (50, 100), fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       fontScale=2, color= (255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "      \n",
    " \n",
    "    #out = np.dstack((out_img*255, out_img*255, out_img*255))\n",
    "    \n",
    "    return result_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5462762",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|                                                            | 0/1260 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_videos/solidWhiteRight.mp4.\n",
      "Moviepy - Writing video output_videos/solidWhiteRight.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  15%|███████▎                                          | 184/1260 [00:45<04:18,  4.16it/s, now=None]"
     ]
    }
   ],
   "source": [
    "# Instanciate cLine classes\n",
    "lineLeft = Line()\n",
    "lineRight = Line()\n",
    "\n",
    "\n",
    "white_output = 'output_videos/solidWhiteRight.mp4'\n",
    "#clip1 = VideoFileClip(\"test_videos/project_video.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"test_videos/project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_frame) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384229a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c275064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate cLine classes\n",
    "lineLeft = Line()\n",
    "lineRight = Line()\n",
    "\n",
    "\n",
    "challenge_output = 'output_videos/challenge_video.mp4'\n",
    "clip2 = VideoFileClip(\"test_videos/challenge_video.mp4\")\n",
    "\n",
    "challenge_clip = clip2.fl_image(process_frame) #NOTE: this function expects color images!!\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5022385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f346b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate cLine classes\n",
    "lineLeft = Line()\n",
    "lineRight = Line()\n",
    "\n",
    "\n",
    "harder_challenge_output = 'output_videos/harder_challenge_video.mp4'\n",
    "clip3 = VideoFileClip(\"test_videos/harder_challenge_video.mp4\")\n",
    "\n",
    "harder_challenge_clip = clip3.fl_image(process_frame) #NOTE: this function expects color images!!\n",
    "%time harder_challenge_clip.write_videofile(harder_challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f55179c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(harder_challenge_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c0c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
