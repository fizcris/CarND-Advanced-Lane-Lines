{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13d48ba",
   "metadata": {},
   "source": [
    "# Videos Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "853e34a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 0. Functions_Clases Pipeline.ipynb to script\n",
      "[NbConvertApp] Writing 23728 bytes to 0. Functions_Clases Pipeline.py\n"
     ]
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "# load helper functions\n",
    "%run -i \"0. Functions_Clases Pipeline.py\"\n",
    "\n",
    "# Load Camera calibration params\n",
    "[ret, mtx, dist, rvecs, tvecs] = pickle.load(open( \"pickle_data/camera_calibration_params.p\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7adf3952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(img):\n",
    "    \n",
    "    ###### Resize image\n",
    "    img = resizeImage(img)\n",
    "    \n",
    "    ###### Undistort image\n",
    "    undistorted = undistort_image(img, mtx, dist)\n",
    "    \n",
    "    ###### Color Enhancement\n",
    "    imageCE = colorEnhancement(img)\n",
    "    \n",
    "    ###### GrayScale\n",
    "    imageGray = grayscale(imageCE)\n",
    "    \n",
    "    ###### Gauss Smoothing\n",
    "    imageGauss = gaussian_blur(imageGray,kernel_size=5)\n",
    "    \n",
    "    #### Edge detection\n",
    "    sbinary = sobel_thresh(imageGauss, sobel_kernel=5, x_thresh=[80,100], y_thresh=[40,100], mag_thresh=[50,255], dir_thresh=[100,200])\n",
    "\n",
    "    #### ROI\n",
    "    ysize =sbinary.shape[0]\n",
    "    xsize =sbinary.shape[1]\n",
    "\n",
    "    ROI_upperWidth = 180 #Width of the upper horizontal straight in px\n",
    "    ROI_upperHeight = 280 #Height of the upper horizontal straight from the bottom of the image in px\n",
    "    ROI_lowerWidth = 950 #Width of the lower horizontal straight in px\n",
    "    ROI_lowerHeight = 50  #Height of the lower horizontal straight  from the bottom of the image in px      \n",
    "\n",
    "    limitLL = ((xsize/2)-(ROI_lowerWidth/2),ysize-ROI_lowerHeight);\n",
    "    limitLR = (xsize - ((xsize/2)-(ROI_lowerWidth/2)),ysize-ROI_lowerHeight);\n",
    "    limitUL = ((xsize/2)-(ROI_upperWidth/2), ysize-ROI_upperHeight);\n",
    "    limitUR = ((xsize/2)+(ROI_upperWidth/2), ysize-ROI_upperHeight);\n",
    "    vertices = np.array([[limitLL,limitUL,limitUR , limitLR]], dtype=np.int32)\n",
    "    \n",
    "    imageROI = region_of_interest(sbinary,vertices)\n",
    "    \n",
    "    \n",
    "    #### Perspective transform\n",
    "    \n",
    "    warped_img,M, Minv = warp_image(imageROI, hwidth = 250 ,offset = 0, height = -600, overplotLines= False )\n",
    "    \n",
    "    #### Find lines\n",
    "    \n",
    "    # Find x line poitns based on histogram values\n",
    "    leftx_base, rightx_base  = find_lane_x_points(warped_img)\n",
    "    \n",
    "    # Update x base points\n",
    "    lineLeft.updateXbase(leftx_base)\n",
    "\n",
    "    lineRight.updateXbase(rightx_base)\n",
    "    \n",
    "    ## Find lane pixels\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(warped_img, lineLeft.bestx, lineRight.bestx, showRectangles = False)\n",
    "    \n",
    "    lineLeft.updatePixels(leftx, lefty)\n",
    "    lineRight.updatePixels(rightx, righty)\n",
    "    \n",
    "    \n",
    "    # Update polynomiasl\n",
    "    coeffs_fit, lineDetected, left_fitx, ploty, img_line  = fit_polynomial(out_img, lineLeft.allx, lineLeft.ally)\n",
    "    lineLeft.updateCoeffsLine(lineDetected, coeffs_fit, left_fitx, ploty,coefLimits=[1,1,10] )\n",
    "\n",
    "    coeffs_fit, lineDetected, right_fitx, ploty, img_line  = fit_polynomial(out_img, lineRight.allx, lineRight.ally)\n",
    "    lineRight.updateCoeffsLine(lineDetected, coeffs_fit,right_fitx,ploty,coefLimits=[1,1,10] )\n",
    "    \n",
    "    \n",
    "    ### Unwarp images\n",
    "    \n",
    "    #color_warp = np.zeros_like(out_img).astype(np.uint8)\n",
    "    color_warp = out_img\n",
    "    #color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    pts_left = np.array([np.transpose(np.vstack([lineLeft.poly_plotx, lineLeft.poly_ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([lineRight.poly_plotx, lineRight.poly_ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "     \n",
    "    #Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "    newwarp = cv2.warpPerspective(color_warp, M, (img.shape[1], img.shape[0])) \n",
    "    result = cv2.addWeighted(img, 1, newwarp, 0.8, 0)\n",
    "    \n",
    "    ### Anotate Radius of curvature\n",
    "    diff, mean, text = checkRadius(lineLeft, lineRight )\n",
    "\n",
    "    result_annotated = cv2.putText(result, text, org= (50, 50), fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   fontScale=2, color= (255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "    ### Anotate Vehicle position\n",
    "    dev, text = calculateDeviation(result, lineLeft,lineRight,)\n",
    "\n",
    "    result_annotated = cv2.putText(result, text, org= (50, 100), fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       fontScale=2, color= (255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "      \n",
    "       \n",
    "    #out = np.dstack((out_img*255, out_img*255, out_img*255))\n",
    "    \n",
    "    return result_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5462762",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|                                                                              | 0/50 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_videos/solidWhiteRight.mp4.\n",
      "Moviepy - Writing video output_videos/solidWhiteRight.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_videos/solidWhiteRight.mp4\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "# Instanciate cLine classes\n",
    "lineLeft = Line()\n",
    "lineRight = Line()\n",
    "\n",
    "\n",
    "white_output = 'output_videos/solidWhiteRight.mp4'\n",
    "clip1 = VideoFileClip(\"test_videos/project_video.mp4\").subclip(0,2)\n",
    "#clip1 = VideoFileClip(\"test_videos/project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_frame) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3384229a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_videos/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c275064e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|                                                                             | 0/485 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_videos/challenge_video.mp4.\n",
      "Moviepy - Writing video output_videos/challenge_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_videos/challenge_video.mp4\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "# Instanciate cLine classes\n",
    "lineLeft = Line()\n",
    "lineRight = Line()\n",
    "\n",
    "\n",
    "challenge_output = 'output_videos/challenge_video.mp4'\n",
    "clip2 = VideoFileClip(\"test_videos/challenge_video.mp4\")\n",
    "\n",
    "challenge_clip = clip2.fl_image(process_frame) #NOTE: this function expects color images!!\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5022385c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_videos/challenge_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f346b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate cLine classes\n",
    "lineLeft = Line()\n",
    "lineRight = Line()\n",
    "\n",
    "\n",
    "harder_challenge_output = 'output_videos/harder_challenge_video.mp4'\n",
    "clip3 = VideoFileClip(\"test_videos/harder_challenge_video.mp4\")\n",
    "\n",
    "harder_challenge_clip = clip3.fl_image(process_frame) #NOTE: this function expects color images!!\n",
    "%time harder_challenge_clip.write_videofile(harder_challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f55179c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(harder_challenge_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720bf777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
